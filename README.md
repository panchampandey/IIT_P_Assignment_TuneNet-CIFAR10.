# IIT_P_Assignment_TuneNet-CIFAR10.
## ğŸ§  Neural Network Hyperparameter Tuning on CIFAR-10
### Course Assignment â€“ Neural Networks in NLP Lab (NNNLP)
### Name: Kumar Pancham Prasar | Roll: 2303res23 | *IIT Patna

#### This project focuses on hyperparameter tuning of a deep neural network classifier using the CIFAR-10 image dataset. The goal is to explore how different hyperparameters affect the modelâ€™s accuracy and performance in multi-class image classification.

#### ğŸ” Key Objectives:
Understand and implement a deep learning pipeline using TensorFlow and Keras

Apply preprocessing techniques on CIFAR-10 images

Experiment with multiple hyperparameters (epochs, optimizers, layers, learning rates)

Analyze model performance using metrics like accuracy and confusion matrix

#### ğŸ› ï¸ Tech Stack:
Languages: Python

Libraries: TensorFlow, Keras, NumPy, Matplotlib, Seaborn, scikit-learn

Dataset: CIFAR-10 (10-class image classification)

# ğŸ“Š Key Components:
âœ… Data loading with cifar10.load_data()

âœ… Preprocessing & label reshaping

âœ… Neural network design using Dense layers

âœ… Optimization with Adam optimizer

âœ… Model evaluation using accuracy score and confusion matrix

âœ… Visualization of results using matplotlib and seaborn

#### ğŸ“ How to Run:
Clone or open this notebook in Google Colab

Ensure necessary libraries (tensorflow, matplotlib, etc.) are installed

Run all cells in order

Modify hyperparameters in the model block to observe changes in performance

#### ğŸ“Œ Learning Outcomes:
Impact of tuning learning rate, layers, and batch size on neural networks

Practical understanding of image classification tasks

Hands-on exposure to CIFAR-10 dataset and CNN fundamentals
